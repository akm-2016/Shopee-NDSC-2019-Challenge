{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanghu\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Sanghu\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import xgboost, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>flormar 7 white cream bb spf 30 40ml</td>\n",
       "      <td>beauty_image/1588591395c5a254bab84042005f2a9f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>maybelline clear smooth all in one bb cream sp...</td>\n",
       "      <td>beauty_image/920985ed9587ea20f58686ea74e20f93.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>murah innisfree eco natural green tea bb cream...</td>\n",
       "      <td>beauty_image/90b40e5710f54352b243fcfb0f5d1d7f.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>loreal white perfect day cream spf 17 pa white...</td>\n",
       "      <td>beauty_image/289c668ef3d70e1d929d602d52d5d78a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>hada labo cc cream ultimate anti aging spf 35 ...</td>\n",
       "      <td>beauty_image/d5b3e652c5822d2306f4560488ec30c6.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid                                              title  \\\n",
       "0   370855998               flormar 7 white cream bb spf 30 40ml   \n",
       "1   637234604  maybelline clear smooth all in one bb cream sp...   \n",
       "2   690282890  murah innisfree eco natural green tea bb cream...   \n",
       "3   930913462  loreal white perfect day cream spf 17 pa white...   \n",
       "4  1039280071  hada labo cc cream ultimate anti aging spf 35 ...   \n",
       "\n",
       "                                          image_path  \n",
       "0  beauty_image/1588591395c5a254bab84042005f2a9f.jpg  \n",
       "1  beauty_image/920985ed9587ea20f58686ea74e20f93.jpg  \n",
       "2  beauty_image/90b40e5710f54352b243fcfb0f5d1d7f.jpg  \n",
       "3  beauty_image/289c668ef3d70e1d929d602d52d5d78a.jpg  \n",
       "4  beauty_image/d5b3e652c5822d2306f4560488ec30c6.jpg  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentdir = os.getcwd()\n",
    "input_data = pd.read_csv(os.path.join(currentdir, r'ndsc-beginner\\train.csv'))\n",
    "input_data.head(5)\n",
    "\n",
    "test = pd.read_csv(os.path.join(currentdir, r'ndsc-beginner\\test.csv'))\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666615, 2)\n",
      "(172402,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                 flormar 7 white cream bb spf 30 40ml\n",
       "1    maybelline clear smooth all in one bb cream sp...\n",
       "2    murah innisfree eco natural green tea bb cream...\n",
       "3    loreal white perfect day cream spf 17 pa white...\n",
       "4    hada labo cc cream ultimate anti aging spf 35 ...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dataset preparation ###\n",
    "\n",
    "# => cannot remove punctuations, stopwords (could remove words like 'make up'), numbers\n",
    "\n",
    "train = input_data[['title', 'Category']]\n",
    "print(train.shape)\n",
    "train.head()\n",
    "\n",
    "test_x = test['title']\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split training data to obtain validation data\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(train['title'], train['Category'])\n",
    "\n",
    "# encoding/converting the text labels to int value (some funcs can only accept int values in sklearn)\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499961, 80091)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Feature Engineering ##\n",
    "\n",
    "# 1 Count Vector - matrix with rows=terms, cols=each document & cell=count of terms in each doucument\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train['title'])\n",
    "\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)\n",
    "xtest_count =  count_vect.transform(test_x)\n",
    "\n",
    "xtrain_count.shape #499961 rows/documents, 80091 words as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanghu\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499961, 5000)\n",
      "(499961, 5000)\n"
     ]
    }
   ],
   "source": [
    "# 2 TFIDF Vector \n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(train['title'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(train['title'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "print(xtrain_tfidf.shape)\n",
    "print(xtrain_tfidf_ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model building ##\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, Count Vectors:  0.6627443685720115\n",
      "NB, WordLevel TF-IDF:  0.6592341017917361\n",
      "NB, N-Gram Vectors:  0.5842524031826419\n"
     ]
    }
   ],
   "source": [
    "#1 Naive Bayes classifier\n",
    "# NB Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# NB Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# NB on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6627443685720115\n"
     ]
    }
   ],
   "source": [
    "nbcount_model = naive_bayes.MultinomialNB().fit(xtrain_count,train_y)\n",
    "nbcount_predictions = nbcount_model.predict(xvalid_count)\n",
    "nbcount_accuracy = metrics.accuracy_score(nbcount_predictions, valid_y)\n",
    "print(nbcount_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbcount_model = naive_bayes.MultinomialNB().fit(xtrain_count,train_y)\n",
    "test_label = nbcount_model.predict(xtest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Category'] = test_label\n",
    "submission = test[['itemid', 'Category']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
